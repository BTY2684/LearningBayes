---
output:
  html_document:
    fig_caption: yes
    keep_md: yes
---
MCMC vs. Optimization
====

```{r global_options, include=FALSE}


```


```{r, echo = F, message=F, warning=F}
set.seed(123)
library(coda)
```


As a first step, we create some test data that will be used to fit our model. Let’s assume a linear relationship between the predictor and the response variable, so we take a linear model and add some noise.

```{r test_data, fig.width=5, fig.height=5}
# This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.
trueA <- 5
trueB <- 0
trueSd <- 10
sampleSize <- 31
 
# Create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)
# Create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)
 
# Plot data
plot(x,y, main="Test Data")
```


## Defining the statistical model 

The next step is to specify the statistical model. We already know that the data was created with a linear relationship y = a*x + b between x and y and a normal error model N(0,sd) with standard deviation sd, so let’s use the same model for the fit and see if we can retrieve our original parameter values. 
<br />


## Derive the likelihood function from the model

For estimating parameters in a Bayesian analysis, we need to derive the likelihood function for the model that we want to fit. The likelihood is the probability (density) with which we would expect the observed data to occur conditional on the parameters of the model that we look at. So, given that our linear model y = b + ax + N(0,sd) takes the parameters (a, b, sd) as an input, we have to return the probability of obtaining the test data above under this model (this sounds more complicated as it is, as you see in the code, we simply calculate the difference between predictions y = b + ax and the observed y, and then we have to look up the probability densities (using dnorm) for such deviations to occur. 

As an illustration, the last lines of the code plot the Likelihood for a range of parameter values of the slope parameter a. The result should look something like the below plot.


```{r likelihood_fucntion, fig.width=5, fig.height=5}
# Likelihood function
likelihood <- function(param){
    pred = param[1]*x + param[2]
    singlelikelihoods = dnorm(y, mean = pred, sd = trueSd, log = T)
    sumll = sum(singlelikelihoods)
    return(sumll)  
}
```

## Plotting the likelihood 

a <- seq(0,10, len = 100)
b <- seq(-10,10, len = 100)
values <- expand.grid(a,b)
values$likelihood <- apply(values, 1, likelihood)
image(a,b,matrix(values$likelihood, nrow = 100))
contours()

## Finding the optimum with optimization

```{r}
startvalue = c(4,3)
optimFit <- optim(c(4,3), likelihood, method="Nelder-Mead", control = list(trace=6, fnscale = -1))

```

## Getting the distribution with MCMC

For an explanation of why this works, see my script on explaining the metropolis-hastings-MCMC

```{r metropolis_algorithm}
run_metropolis_MCMC <- function(startvalue, iterations){
    chain = array(dim = c(iterations+1,3))
    chain[1,] = startvalue
    for (i in 1:iterations){
        proposal = return(rnorm(2,mean = chain[i,], sd= c(0.1,0.5)))
        probab = exp(posterior(proposal) - posterior(chain[i,]))
        if (runif(1) < probab){
            chain[i+1,] = proposal
        }else{
            chain[i+1,] = chain[i,]
        }
    }
    return(chain)
}

chain = run_metropolis_MCMC(startvalue, 10000)
 
burnIn = 5000
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
```



```{r, fig.width = 7, fig.height = 7}
plot(mcmc(chain[-(1:burnIn),]))
summary(mcmc(chain)) 
```





---
**Copyright, reuse and updates**: By Florian Hartig. Updates will be posted at https://github.com/florianhartig/LearningBayes. Reuse permitted under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License
