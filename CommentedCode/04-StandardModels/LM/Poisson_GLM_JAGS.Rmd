---
title: "Bayesian analysis of a Poisson GLM"
author: "Felix May"
date: "Monday, June 22, 2015"
output:
  html_document:
    keep_md: yes
---

```{r global_options, include=F}
knitr::opts_chunk$set(fig.width=5, fig.height=5)
```

***

This example is a simplified version of chapter 15 in **Kery (2010) Introduction to WinBUGs for Ecologists, pages 193 -- 202.** 

We analyse the relationship between wing length and mite infection of dragon flies. Mite infection is quantified as the number of mites on each dragonfly. That means we have count data that we model with a Poisson error distribution.

### 1. Simulate data

This time we center the numeric exlanatory variable (Winglength) from the beginning. And in the Poisson model we use a log-link function and thus the exponential function as inverse of the link function.

```{r}
set.seed(12345)

n1 <- 100                                    # sample size
Winglength <- sort(runif(n1,5,8))            # explanatory variable
cWinglength <- Winglength - mean(Winglength) # center explanatory variable for easier model convergence

a.true <- 2.5    # intercept
b.true <- - 1.1  # slope

eta1 <- a.true+b.true*cWinglength     #linear predictor
lambda.true <- exp(eta1)              # inverse log-link function 

Mites <- rpois(n1,lambda=lambda.true) # add Poisson error

plot(Mites~cWinglength,xlab="Winglength [cm]",ylab=" No. of mites")
lines(lambda.true ~ cWinglength,col="blue")
```


###2. Bayesian analysis using JAGS

In the model specification we code the error distribution and the inverse link function in close correspondence to the data simulation. We use wide normal distributions as uninformative priors on the model parameters a and b.
Please note that there is no sigma as in the normal distribution, because in the Poisson distribution mean = variance by definition.

```{r}
modelCode <- "
   model{
      # Likelihood
      for(i in 1:n.max){
         y[i] ~ dpois(lambda[i])  # poisson error distribution
         lambda[i] <- exp(eta[i]) # inverse link function
         eta[i] <- a + b*x[i]     # linear predictor
      }
      # Prior distributions
      a ~ dnorm(0,0.001)
      b ~ dnorm(0,0.001)
   }"
```

Preparation for running JAGS

```{r}
Data <- list(y = Mites, x = cWinglength, n.max = length(Mites))
inits.fn <- function() list(a = rnorm(1,mean=0,sd=10), b = rnorm(1,mean=0,sd=10))
```

And call JAGS

```{r,message=FALSE}
library(R2jags)
jags.fit <- jags(data=Data, 
                 inits=inits.fn,
                 parameters.to.save=c("a","b"), 
                 model.file=textConnection(modelCode),
                 n.chains=3, 
                 n.iter=25000,
                 n.burnin=5000,
                 n.thin=20,
                 DIC=F)
```

The exploration of the JAGS output should be routine by now ...

```{r,fig.width=7,fig.height=7}
plot(jags.fit)
print(jags.fit)

jags.mcmc <- as.mcmc(jags.fit)

plot(jags.mcmc)     # check convergence and posterior distributions

summary(jags.mcmc)
gelman.diag(jags.mcmc)  # check convergence
HPDinterval(jags.mcmc)  # posterior credible intervals

```

In the traceplots we see that there is a strange first value in the chains. This should not happen with an appropriate burn-in sample. We used 5000 burn-in samples, so this strange first value seems to be a bugs of JAGS. We simply remove the strange first value in the lumping of the 3 chains.

```{r}
head(jags.mcmc[[1]])
head(jags.mcmc[[2]])
head(jags.mcmc[[3]])

jags.mcmc.lumped <- as.mcmc(rbind(jags.mcmc[[1]][-1,],
                                  jags.mcmc[[2]][-1,],
                                  jags.mcmc[[3]][-1,]))
```

We again check the plots and assess the correlation among the parameters.

```{r}
plot(jags.mcmc.lumped)

pairs(as.data.frame(jags.mcmc.lumped))
cor(as.data.frame(jags.mcmc.lumped))
```

We find that despite the centering of Winglength there is correlation between the samples of a and b. This is not a problem or mistake in our analysis, but this is a common finding for more complex, non-linear models.


###3. Predictions and uncertainty

As a last step we want to plot the data, the predictions and their uncertainty. We again use a loop over all MCMC samples. This time we only calculate the predictive uncertainty for a single measurements, that means we include the random error component of the Poisson distribution.

```{r}
pred1 <- matrix(NA,nrow=nrow(jags.mcmc.lumped),ncol=length(Mites))
for (i in 1:nrow(pred1)){
   lambda.pred <- exp(jags.mcmc.lumped[i,"a"] + cWinglength*jags.mcmc.lumped[i,"b"])
   pred1[i,] <- rpois(length(cWinglength),lambda=lambda.pred) # Poisson error                 
}
```

From this matrix we then calculate the 95% credible intervals.

```{r}
lower2 <- apply(pred1,MARGIN=2,quantile,prob=0.025)
upper2 <- apply(pred1,MARGIN=2,quantile,prob=0.975)
```

And finally the posterior mean prediction.

```{r}
posterior.mean.pred <- exp(mean(jags.mcmc.lumped[i,"a"]) + cWinglength*mean(jags.mcmc.lumped[i,"b"]))
```

Here is the plot we would like to have in the end. We also add the "true" line to see that the Bayesian estimation is pretty close to the simulated model.

```{r}
plot(Mites~cWinglength,xlab="Winglength [cm]",ylab=" No. of mites")

lines(cWinglength,posterior.mean.pred,col="red",lwd=2)

lines(cWinglength,lower2,col="green",lwd=1,lty=2)
lines(cWinglength,upper2,col="green",lwd=1,lty=2)

lines(cWinglength,lambda.true,col="blue") # "true" model
```


**Copyright, reuse and updates**: copyright belongs to author(s) (see author statement at the top of the file). Reuse permitted under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License

Sourcecode and potential future updates available at http://florianhartig.github.io/LearningBayes/ (follow the link under code, and then navigate through the topics to find the location of the file)
